{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-competitions/kaggle/30894/logos/header.png)\n# G-Research Crypto - Modélisation (FR)\n\nDans le concours de prédiction G-Research Crypto, les participants ont le défi de prédire les rendements des prix sur un ensemble de crypto-monnaies majeures.\n\nRéférences utilisées : \n* [Tutorial to the G-Research Crypto Competition](https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition)\n* [G-Research Crypto - Starter XGB Pipeline](https://www.kaggle.com/tarlannazarov/g-research-crypto-starter-xgb-pipeline)\n* [LGDM model with new features better generalization](https://www.kaggle.com/swaralipibose/lgdm-model-with-new-features-better-generalization)","metadata":{}},{"cell_type":"markdown","source":"---\n# Chargement","metadata":{}},{"cell_type":"markdown","source":"## Libraries et Fonctions","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn import preprocessing, linear_model, pipeline\nfrom lightgbm import LGBMRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-24T15:32:57.149668Z","iopub.execute_input":"2021-11-24T15:32:57.150425Z","iopub.status.idle":"2021-11-24T15:33:00.007114Z","shell.execute_reply.started":"2021-11-24T15:32:57.150326Z","shell.execute_reply":"2021-11-24T15:33:00.006344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats.pearsonr([1,20,1],[-6,-5,-6])[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:34:48.25587Z","iopub.execute_input":"2021-11-24T15:34:48.256285Z","iopub.status.idle":"2021-11-24T15:34:48.267091Z","shell.execute_reply.started":"2021-11-24T15:34:48.256245Z","shell.execute_reply":"2021-11-24T15:34:48.266347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ndef ponderation(corrs):\n    \"\"\"Moyenne pondérée des corrélations positives.\n    \"\"\"\n    tmp = (df_asset_details['Weight'] * corrs)\n    return tmp[tmp > 0].sum() / df_asset_details['Weight'].sum()\n#     return (df_asset_details['Weight'] * corrs).abs().sum() / df_asset_details['Weight'].sum()\n\ndef plot_feature_importance(feature_names, model):\n    fi_df = pd.DataFrame()\n    fi_df['features'] = feature_names\n    if type(model) == xgb.XGBRegressor:\n        fi_df['importance'] = model.feature_importances_\n    elif type(model) == LGBMRegressor:\n        fi_df['importance'] = model.booster_.feature_importance(importance_type=\"gain\")\n    else:\n        print('Pas de feature_importances_ configuré pour ce modèle.')\n        return None\n\n    fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n    sns.barplot(y='importance', x='features', data=fi_df.sort_values(by=['importance'], ascending=False), ax=ax)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right')\n    plt.show()\n    \ndef RSI(close: pd.DataFrame, period: int = 14) -> pd.Series:\n    # https://gist.github.com/jmoz/1f93b264650376131ed65875782df386\n    \"\"\"See source https://github.com/peerchemist/finta\n    and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\n    Relative Strength Index (RSI) is a momentum oscillator that measures the speed and change of price movements.\n    RSI oscillates between zero and 100. Traditionally, and according to Wilder, RSI is considered overbought when above 70 and oversold when below 30.\n    Signals can also be generated by looking for divergences, failure swings and centerline crossovers.\n    RSI can also be used to identify the general trend.\n    \"\"\"\n    delta = close.diff()\n    up, down = delta.copy(), delta.copy()\n    up[up < 0] = 0\n    down[down > 0] = 0\n\n    _gain = up.ewm(com=(period - 1), min_periods=period).mean()\n    _loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\n    RS = _gain / _loss\n    return pd.Series(100 - (100 / (1 + RS)))\n    \ndef plot_corrs(c_train, c_test):    \n    pd.DataFrame(data={\n        f'Entrainement (avg:{ponderation(c_train):.2f})': c_train, \n        f'Test (avg:{ponderation(c_test):.2f})': c_test\n    }).plot.bar(figsize=(10,5))\n    plt.xlabel('Crypto-monnaies')\n    plt.ylabel('Corrélation de Pearson')\n    plt.plot([0,13],[0,0], '--k')\n    plt.xticks(range(14), df_asset_details.Asset_Name.values, rotation=30, ha='right')\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-24T13:54:40.905806Z","iopub.execute_input":"2021-11-24T13:54:40.906052Z","iopub.status.idle":"2021-11-24T13:54:40.929951Z","shell.execute_reply.started":"2021-11-24T13:54:40.906017Z","shell.execute_reply":"2021-11-24T13:54:40.929264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Données","metadata":{}},{"cell_type":"code","source":"data_folder = \"../input/g-research-crypto-forecasting/\"\ndf = pd.read_csv(data_folder + 'train.csv').pipe(reduce_mem_usage)\ndf = df.sort_values(by=['timestamp','Asset_ID'])\ndf = df.iloc[:-16*14]  # Suppression des 16 dernières minutes sans Target\ndf_train = df[df.timestamp < 1623542400]  # Avant '2021-06-13 00:00:00'\ndf_asset_details = pd.read_csv(data_folder + 'asset_details.csv').sort_values(\"Asset_ID\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T13:54:40.931446Z","iopub.execute_input":"2021-11-24T13:54:40.931885Z","iopub.status.idle":"2021-11-24T13:55:46.486351Z","shell.execute_reply.started":"2021-11-24T13:54:40.931847Z","shell.execute_reply":"2021-11-24T13:55:46.485586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDs = df_asset_details.Asset_ID.values\ntmin, tmax = df_train['timestamp'].min(), df_train['timestamp'].max()\ndf_train = df_train.set_index('timestamp')\ndf_tmp = pd.DataFrame()\nfor i in IDs:\n    sub_reindexed = df_train.loc[df_train['Asset_ID'] == i].reindex(range(tmin, tmax+60, 60), method='bfill')\n    df_tmp = pd.concat([df_tmp, sub_reindexed], axis=0)\n    if i == 1:\n        df_btc = sub_reindexed\n        \ndf_train = df_tmp.reset_index()\ndf_btc = df_btc.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T13:55:46.488214Z","iopub.execute_input":"2021-11-24T13:55:46.488489Z","iopub.status.idle":"2021-11-24T13:55:54.965142Z","shell.execute_reply.started":"2021-11-24T13:55:46.488452Z","shell.execute_reply":"2021-11-24T13:55:54.964365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Préparation","metadata":{}},{"cell_type":"markdown","source":"## Cibles de prédiction et évaluation\nCe concours de prévision vise à prédire les rendements dans un futur proche des prix $P^a$, pour chaque actif $a$.\nPour chaque ligne de l'ensemble de données, nous incluons la cible de prédiction, `Target`.\nLa cible est dérivée des **log return** ($R^a$) sur **15 minutes** :\n$$R^a(t)=\\log(P^a(t+16) / P^a(t+1))$$\n\nLes rendements des actifs cryptographiques sont fortement corrélés, suivant dans une large mesure le marché global de la cryptographie.\nComme on nous pousse à tester notre capacité à prédire les rendements d'actifs individuels,  une résidualisation linéaire a été effectuée, en supprimant le signal de marché des rendements d'actifs individuels lors de la création de `Target`. \nPlus en détail, si $M(t)$ est la moyenne pondérée des rendements du marché, la cible est :\n$$M(t) = \\frac{\\sum_{a}{w^aR^a(t))}}{\\sum_{a}{w^a}}$$\n$$\\beta^a = \\frac{⟨M⋅R^a⟩}{⟨M^2⟩}$$\n$$\\text{Target}^a(t) = R^a(t)−\\beta^aM(t)$$\noù la parenthèse $⟨.⟩$ représente la **moyenne mobile** au fil du temps (fenêtres de 3750 minutes), et les mêmes pondérations d'actifs ont été utilisées pour la métrique d'évaluation.\n\nCertaines lignes ont des valeurs nulles pour les cibles en raison de valeurs manquantes dans les prix futurs. \nLes lignes avec des valeurs NULL dans l'ensemble de test sont ignorées à des fins de notation.\n\nDans la compétition, les prédictions seront évaluées sur une version pondérée du coefficient de corrélation de Pearson, avec des pondérations données par la colonne `Weight` dans le fichier `asset_details.csv`.","metadata":{}},{"cell_type":"markdown","source":"## Feature design\nAvant de chercher des caractéristiques, il y a quelques mises en garde à prendre en compte :\n* pas de fuite : nous ne pouvons pas utiliser une fonctionnalité qui utilise les informations futures (il s'agit d'une tâche de prévision)\n* caractéristiques stationnaires : les caractéristiques doivent fonctionner à tout moment (les échelles doivent être stationnaires sur des périodes de temps)\n\nQuelques caractéristiques pertinentes potentielles :\n* ...","metadata":{}},{"cell_type":"markdown","source":"### Indicateurs techniques","metadata":{}},{"cell_type":"code","source":"def get_features(df_asset, df_btc):\n    df = df_asset.copy()\n    \n#     df['price_change'] = df['Close'] / df['Open']\n#     df['log_price_change'] = np.log1p(df['price_change'])\n#     df['trade'] = df['Close'] - df['Open']\n#     df['candle_len'] = np.abs(df['trade'])\n    df['gtrade'] = (df['Close'] - df['Open']) / (df['Count'] + 1)\n    df['mean_trade'] = df['Volume'] / (df['Count'] + 1)\n    \n    df['high2low'] = df['High'] / df['Low']\n    df['spread'] = df['High'] - df['Low']\n    median_price = df[['Open', 'High', 'Low', 'Close']].median(axis=1)\n    df['high2median'] = df['High'] / median_price\n    df['low2median'] = df['Low'] / median_price\n    \n    # df['upper_shadow'] = df['High'] / df[['Close', 'Open']].max(axis=1)\n    df['upper_shadow'] = df['High'] - df[['Close', 'Open']].max(axis=1)\n    # df['lower_shadow'] = df[['Close', 'Open']].min(axis=1) / df['Low']\n    df['lower_shadow'] = df[['Close', 'Open']].min(axis=1) - df['Low']\n#     df['upper_shadow_log'] = np.log1p(df['upper_shadow'])\n#     df['lower_shadow_log'] = np.log1p(df['lower_shadow'])\n    \n    times = pd.to_datetime(df['timestamp'], unit=\"s\", infer_datetime_format=True)\n    df[\"dayofweek\"] = times.dt.dayofweek \n    df[\"RSI_14\"] = RSI(df[\"Close\"], 14)\n    \n    df[\"dCloseBTC\"] = df_btc.loc[df_btc['timestamp'].isin(df['timestamp']), 'Close'].diff().values\n#     df['d2CloseBTC'] = df[\"dCloseBTC\"].diff()\n    for t in [3, 5, 15, 30, 60]:\n        # Lags\n        df[f\"dCloseBTC_t-{t}\"] = df[\"dCloseBTC\"].shift(t)\n#         df[f\"d2CloseBTC_t-{t}\"] = df[\"d2CloseBTC\"].shift(t)\n        \n        # Aggrégations\n        df[f\"mdClose_t-{t}\"] = df[\"Close\"].diff().rolling(t).mean()\n    \n    df = df.drop(columns=['timestamp', 'Asset_ID'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-23T22:48:44.714063Z","iopub.execute_input":"2021-11-23T22:48:44.714741Z","iopub.status.idle":"2021-11-23T22:48:44.726437Z","shell.execute_reply.started":"2021-11-23T22:48:44.714703Z","shell.execute_reply":"2021-11-23T22:48:44.725777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Découpage\nIl faut construire des Folds (sous échantillons) indépendants. \nPour éviter de complexifier la tache avec des DataFrame différentes, on passera par des listes d'index.","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import TimeSeriesSplit\n# a = list(range(42))\n# list(TimeSeriesSplit(n_splits=3,).split(a))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:44:07.853267Z","iopub.execute_input":"2021-11-23T20:44:07.853662Z","iopub.status.idle":"2021-11-23T20:44:07.859039Z","shell.execute_reply.started":"2021-11-23T20:44:07.853625Z","shell.execute_reply":"2021-11-23T20:44:07.858349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# time_ids = df_train[\"timestamp\"].unique()\n# ntimes = len(time_ids)\n\n# n_fold = 5\n# splits = 0.7\n\n# # 1 mois d'embargo\n# embargo_train_test = 60*24*30\n# embargo_fold = 60*24*30\n\n# time_per_fold = (ntimes - 5*embargo_train_test - 5*embargo_fold)/5\n# train_len = splits*time_per_fold \n# test_len = (1-splits)*time_per_fold\n\n# fold_start = [np.int(i*(ntimes+1)/5) for i in range(6)]\n\n# for i in range(n_fold):\n#     time_folds = time_ids[fold_start[i]:fold_start[i+1]-1]\n#     df_fold = train_df[train_df.timestamp.isin(time_folds)]\n#     df_fold.to_parquet('df_fold_'+str(i)+'.parquet')\n    \n# del train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:44:07.860698Z","iopub.execute_input":"2021-11-23T20:44:07.861641Z","iopub.status.idle":"2021-11-23T20:44:07.868733Z","shell.execute_reply.started":"2021-11-23T20:44:07.861603Z","shell.execute_reply":"2021-11-23T20:44:07.867934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modèles","metadata":{}},{"cell_type":"code","source":"template_lin = (\n    linear_model.LinearRegression,\n    {})","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:50:19.756115Z","iopub.execute_input":"2021-11-23T20:50:19.756649Z","iopub.status.idle":"2021-11-23T20:50:19.760515Z","shell.execute_reply.started":"2021-11-23T20:50:19.756614Z","shell.execute_reply":"2021-11-23T20:50:19.759493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template_lgbm = (\n    LGBMRegressor,\n    {\n        'n_estimators': 1000,\n        'learning_rate': 0.09,\n        # 'metric': 'rmse',\n        'num_leaves': 500,\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'max_depth': 10,\n        # 'subsample': 0.72,\n        # 'subsample_freq': 4,\n        # 'feature_fraction': 0.4,\n        # 'lambda_l1': 1,\n        # 'lambda_l2': 1,\n        # 'seed': 46,\n    })","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:50:20.013584Z","iopub.execute_input":"2021-11-23T20:50:20.013963Z","iopub.status.idle":"2021-11-23T20:50:20.018966Z","shell.execute_reply.started":"2021-11-23T20:50:20.01393Z","shell.execute_reply":"2021-11-23T20:50:20.018155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template_xgb = (\n    xgb.XGBRegressor,\n    {\n        'n_estimators': 1000,\n        'learning_rate': 0.09,\n        'max_depth': 10,\n        # 'subsample': 0.9,\n        # 'colsample_bytree': 0.7,\n        # 'colsample_bylevel': 0.75, \n#         'missing': -999,\n#         'random_state': 1111,\n        'tree_method': 'gpu_hist',\n    })","metadata":{"execution":{"iopub.status.busy":"2021-11-23T21:38:22.131856Z","iopub.execute_input":"2021-11-23T21:38:22.132568Z","iopub.status.idle":"2021-11-23T21:38:22.136975Z","shell.execute_reply.started":"2021-11-23T21:38:22.13253Z","shell.execute_reply":"2021-11-23T21:38:22.136256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Modélisation","metadata":{}},{"cell_type":"code","source":"def get_Xy_and_model_for_asset(template_model, df_train, asset_id):\n    df = df_train[df_train[\"Asset_ID\"] == asset_id]#[-14*13000:]\n    \n    df_proc = get_features(df.drop(columns='Target'), df_btc)#[-14*13000:])\n    df_proc['y'] = df['Target']\n    df_proc = df_proc.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n    \n    X = df_proc.drop(\"y\", axis=1)\n    y = df_proc[\"y\"]\n    \n    pipe = pipeline.Pipeline(steps=[\n        ('scaler', preprocessing.StandardScaler()),\n        ('model', template_model[0](**template_model[1]))])\n    pipe.fit(X, y)\n    lastX = df.iloc[-70:].drop(columns='Target')\n    \n    # Prédiction sur les 2000 derniers éléments pour accélérer le processus\n    y_pred = pipe.predict(X[-2000:])\n    return lastX, pipe, y[-2000:], y_pred\n\ndef procedure(template_model):\n    models = {}\n    lastXs = {}\n    corrs = []\n    for i, (asset_id, asset_weight, asset_name) in df_asset_details.iterrows():\n        lastX, model, y, y_pred = get_Xy_and_model_for_asset(template_model, df_train, asset_id)    \n        corr = stats.pearsonr(y, y_pred)[0]\n        models[asset_id] = model\n        lastXs[asset_id] = lastX\n        corrs.append(corr)\n        print(f\"Entrainement du modèle for {asset_name:<16} (ID={asset_id:>2}): {corr:5.2f}\")\n    print(f\"{ponderation(corrs):5.2f} <-- Moyenne pondérée des corrélations absolues\")\n    return models, lastXs, corrs\n\ndef test(models):\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    Xs = dict(lastXs)\n    timestamps = df_test.iloc[100*14:]['timestamp'].unique()\n    for timestamp in timestamps: \n        if not (timestamp % (6*len(timestamps))):\n            print(f\"{1+ (timestamp-timestamps[0]) // (6*len(timestamps)):>2} / 10\")\n\n        t_test = df_test.loc[df_test['timestamp'] == timestamp]\n        for j , row in t_test.iterrows():\n            ID = row['Asset_ID']\n            model = models[ID]\n            Xs[ID] = Xs[ID].shift(-1)\n            Xs[ID].iloc[-1] = row[:-2]\n            \n            x_test = get_features(Xs[ID], df_btc_test)\n            y_pred = model.predict(x_test[-1:])[0]\n\n            df_test.loc[row.name, 'Pred'] = y_pred\n        \n    corrs = []\n    for i, row in df_asset_details.iterrows():\n        ID = row['Asset_ID']\n        corr = stats.pearsonr(\n            df_test[100*14:].loc[df_test[100*14:]['Asset_ID'] == ID, 'Target'].values, \n            df_test[100*14:].loc[df_test[100*14:]['Asset_ID'] == ID, 'Pred'].values\n        )[0]\n        print(f\"{corr:5.2f}  {row['Asset_Name']}\")\n        corrs.append(corr)\n    print(f\"{ponderation(corrs):5.2f} <-- Moyenne pondérée des corrélations absolues\")\n    return corrs\n\ndef test2(models):\n    corrs = []\n    for i, (asset_id, asset_weight, asset_name) in df_asset_details.iterrows():\n        df = df_test[df_test[\"Asset_ID\"] == asset_id]\n        df_proc = get_features(df.drop(columns=['Target','Pred']), df_btc_test)[100:]\n        df_proc['y'] = df['Target']\n        df_proc = df_proc.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n\n        X = df_proc.drop(\"y\", axis=1)\n        y_true = df_proc[\"y\"]\n        y_pred = models[asset_id].predict(X)  \n          \n        corr = stats.pearsonr(y_true, y_pred)[0]\n        corrs.append(corr)\n        print(f\"{asset_name:<16} (ID={asset_id:>2}): {corr:5.2f}\")\n    print(f\"{ponderation(corrs):5.2f} <-- Moyenne pondérée des corrélations absolues\")\n    return corrs","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:54:04.274041Z","iopub.execute_input":"2021-11-23T20:54:04.274603Z","iopub.status.idle":"2021-11-23T20:54:04.296192Z","shell.execute_reply.started":"2021-11-23T20:54:04.274566Z","shell.execute_reply":"2021-11-23T20:54:04.29548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 7,54s pour 10 minutes &rarr; 30h pour tout le jeu de test...  \nTODO  &rarr; optimiser","metadata":{}},{"cell_type":"markdown","source":"## Données de Test manuel","metadata":{}},{"cell_type":"code","source":"# Après '2021-06-13 00:00:00' et pour 4 minutes\n# df_test = df[df.index >= 1623542400].iloc[:4*14].reset_index().sort_values(by=['timestamp','Asset_ID']).reset_index(drop=True)\n# df_test = df[df.timestamp > 1623542400]  # Après '2021-06-13 00:00:00'\ndf_test = pd.read_csv(data_folder + 'supplemental_train.csv')\ndf_test = df_test[:-16*14]\n# df_test = df_test[:200*14]\ndf_test = pd.concat([df_train.iloc[-100*14:], df_test])  # Ajout des dernieres valeurs d'entrainement\n# df_test = df_test.sort_values(by=['timestamp','Asset_ID'])\n\ntmin, tmax = df_test['timestamp'].min(), df_test['timestamp'].max()\ndf_test = df_test.set_index('timestamp')\ndf_btc_test = df_test.loc[df_test['Asset_ID'] == 1].reindex(range(tmin, tmax+60, 60), method='bfill')\ndf_test = df_test.reset_index()\ndf_btc_test = df_btc_test.reset_index()\ndf_test['Pred'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2021-11-24T13:56:55.779047Z","iopub.execute_input":"2021-11-24T13:56:55.7793Z","iopub.status.idle":"2021-11-24T13:56:58.771457Z","shell.execute_reply.started":"2021-11-24T13:56:55.779268Z","shell.execute_reply":"2021-11-24T13:56:58.770596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_btc)/(len(df_btc)+ len(df_btc_test)), len(df_btc_test)/(len(df_btc)+ len(df_btc_test))","metadata":{"execution":{"iopub.status.busy":"2021-11-24T13:56:59.253072Z","iopub.execute_input":"2021-11-24T13:56:59.253753Z","iopub.status.idle":"2021-11-24T13:56:59.261243Z","shell.execute_reply.started":"2021-11-24T13:56:59.253711Z","shell.execute_reply":"2021-11-24T13:56:59.260364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linéaire","metadata":{}},{"cell_type":"code","source":"%%time\nmodels_lin, lastXs, corrs_train_lin = procedure(template_lin)\ncorrs_test_lin = test(models_lin)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-23T22:00:46.82836Z","iopub.execute_input":"2021-11-23T22:00:46.82862Z","iopub.status.idle":"2021-11-23T22:03:41.697884Z","shell.execute_reply.started":"2021-11-23T22:00:46.82859Z","shell.execute_reply":"2021-11-23T22:03:41.697183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plus rapide mais différent. TODO: Vérifier les fonctions\ncorrs_test_lin2 = test2(models_lin)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-23T15:07:23.912793Z","iopub.execute_input":"2021-11-23T15:07:23.913327Z","iopub.status.idle":"2021-11-23T15:07:24.345624Z","shell.execute_reply.started":"2021-11-23T15:07:23.91329Z","shell.execute_reply":"2021-11-23T15:07:24.344887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_corrs(corrs_train_lin, corrs_test_lin)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T23:35:40.085697Z","iopub.execute_input":"2021-11-23T23:35:40.085967Z","iopub.status.idle":"2021-11-23T23:35:40.391322Z","shell.execute_reply.started":"2021-11-23T23:35:40.085936Z","shell.execute_reply":"2021-11-23T23:35:40.390683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBMRegressor","metadata":{}},{"cell_type":"code","source":"%%time\nmodels_lgbm, lastXs, corrs_train_lgbm = procedure(template_lgbm)\ncorrs_test_lgbm = test(models_lgbm)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-23T22:05:50.242284Z","iopub.execute_input":"2021-11-23T22:05:50.242549Z","iopub.status.idle":"2021-11-23T22:45:49.082508Z","shell.execute_reply.started":"2021-11-23T22:05:50.242519Z","shell.execute_reply":"2021-11-23T22:45:49.081559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Test de l'interface\nlastX = lastXs[0]\n# lastX = lastX.shift(-1)\n# lastX.iloc[-1] = df_train[df_train[\"Asset_ID\"] == 0].iloc[-1]\n\nx = get_features(lastX, df_btc)\nfeature_names = x.columns\ny_pred = models_lgbm[0].predict(x[-1:])[0]\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-23T22:45:54.520246Z","iopub.execute_input":"2021-11-23T22:45:54.520503Z","iopub.status.idle":"2021-11-23T22:45:54.590141Z","shell.execute_reply.started":"2021-11-23T22:45:54.520475Z","shell.execute_reply":"2021-11-23T22:45:54.58962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_corrs(corrs_train_lgbm, corrs_test_lgbm)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T23:35:51.016151Z","iopub.execute_input":"2021-11-23T23:35:51.016413Z","iopub.status.idle":"2021-11-23T23:35:51.507024Z","shell.execute_reply.started":"2021-11-23T23:35:51.016386Z","shell.execute_reply":"2021-11-23T23:35:51.506319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Précédemment meilleur avec plus de caractéristiques\n# plot_corrs(corrs_train_lgbm, corrs_test_lgbm)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T21:32:56.10321Z","iopub.execute_input":"2021-11-23T21:32:56.103448Z","iopub.status.idle":"2021-11-23T21:32:56.419103Z","shell.execute_reply.started":"2021-11-23T21:32:56.103412Z","shell.execute_reply":"2021-11-23T21:32:56.418147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nID = 9\nplt.figure(figsize=(15,3))\nplt.plot(df_test.loc[df_test['Asset_ID'] == ID, 'Target'].values, label='Réel')\nplt.plot(df_test.loc[df_test['Asset_ID'] == ID, 'Pred'].values*(3), label='Prédiction')\nplt.xlabel('Minutes')\nplt.ylabel('Cible')\nplt.plot([0,199],[0,0],'k--')\nplt.xlim(0,199)\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-11-23T22:48:12.464499Z","iopub.execute_input":"2021-11-23T22:48:12.464783Z","iopub.status.idle":"2021-11-23T22:48:12.712304Z","shell.execute_reply.started":"2021-11-23T22:48:12.464752Z","shell.execute_reply":"2021-11-23T22:48:12.711632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(feature_names, models_lgbm[9]['model'])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T23:16:08.655388Z","iopub.execute_input":"2021-11-23T23:16:08.655781Z","iopub.status.idle":"2021-11-23T23:16:09.102908Z","shell.execute_reply.started":"2021-11-23T23:16:08.655739Z","shell.execute_reply":"2021-11-23T23:16:09.102246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegressor","metadata":{}},{"cell_type":"code","source":"%%time\nmodels_xgb, lastXs, corrs_train_xgb = procedure(template_xgb)\ncorrs_test_xgb = test(models_xgb)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-23T21:42:09.05084Z","iopub.execute_input":"2021-11-23T21:42:09.051112Z","iopub.status.idle":"2021-11-23T21:56:13.479832Z","shell.execute_reply.started":"2021-11-23T21:42:09.051081Z","shell.execute_reply":"2021-11-23T21:56:13.479154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Test de l'interface\nlastX = lastXs[0]\n# lastX = lastX.shift(-1)\n# lastX.iloc[-1] = df_train[df_train[\"Asset_ID\"] == 0].iloc[-1]\n\nx = get_features(lastX, df_btc)\nfeature_names = x.columns\ny_pred = models_xgb[0].predict(x[-1:])[0]\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-23T21:58:56.575118Z","iopub.execute_input":"2021-11-23T21:58:56.575884Z","iopub.status.idle":"2021-11-23T21:58:56.643067Z","shell.execute_reply.started":"2021-11-23T21:58:56.575813Z","shell.execute_reply":"2021-11-23T21:58:56.642391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_corrs(corrs_train_xgb, corrs_test_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T23:36:02.759664Z","iopub.execute_input":"2021-11-23T23:36:02.759943Z","iopub.status.idle":"2021-11-23T23:36:03.068478Z","shell.execute_reply.started":"2021-11-23T23:36:02.759912Z","shell.execute_reply":"2021-11-23T23:36:03.067743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nID = 9\nplt.figure(figsize=(15,3))\nplt.plot(df_test.loc[df_test['Asset_ID'] == ID, 'Target'].values, label='Réel')\nplt.plot(df_test.loc[df_test['Asset_ID'] == ID, 'Pred'].values*(2), label='Prédiction')\nplt.xlabel('Minutes')\nplt.ylabel('Cible')\nplt.plot([0,199],[0,0],'k--')\nplt.xlim(0,199)\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-11-23T22:00:16.765813Z","iopub.execute_input":"2021-11-23T22:00:16.766431Z","iopub.status.idle":"2021-11-23T22:00:17.061091Z","shell.execute_reply.started":"2021-11-23T22:00:16.766392Z","shell.execute_reply":"2021-11-23T22:00:17.060366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(feature_names, models_xgb[9]['model'])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T23:16:24.779955Z","iopub.execute_input":"2021-11-23T23:16:24.780677Z","iopub.status.idle":"2021-11-23T23:16:25.238534Z","shell.execute_reply.started":"2021-11-23T23:16:24.78064Z","shell.execute_reply":"2021-11-23T23:16:25.237713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparaison","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(\n    data={\n        'Entrainement': [\n            ponderation(corrs_train_lin),\n            ponderation(corrs_train_lgbm),\n            ponderation(corrs_train_xgb)],\n        'Test': [\n            ponderation(corrs_test_lin),\n            ponderation(corrs_test_lgbm),\n            ponderation(corrs_test_xgb)]},\n    index=['Linéaire','LGBM','XGBoost']\n).plot.bar(rot=0)\nplt.ylabel('Corrélation de Pearson');","metadata":{"execution":{"iopub.status.busy":"2021-11-23T23:36:12.693981Z","iopub.execute_input":"2021-11-23T23:36:12.694507Z","iopub.status.idle":"2021-11-23T23:36:12.931305Z","shell.execute_reply.started":"2021-11-23T23:36:12.694469Z","shell.execute_reply":"2021-11-23T23:36:12.930635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Sousmission","metadata":{}},{"cell_type":"markdown","source":"Il s'agit d'un concours de code, dans lequel nous devons soumettre une Notebook pour qu'elle soit exécuté avec les données privées cachées. \nLa Notebook doit utiliser l'API de série temporelle python fournie, qui garantit que les modèles n'apparaissent pas dans le temps. \nPour utiliser l'API, les instructions et l'exemple sont détaillées ici : [Detailed API Introduction](https://www.kaggle.com/sohier/detailed-api-introduction) et [Basic Submission Template](https://www.kaggle.com/sohier/basic-submission-template).","metadata":{}},{"cell_type":"code","source":"import gresearch_crypto\nenv = gresearch_crypto.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:20:28.089712Z","iopub.execute_input":"2021-11-16T18:20:28.090509Z","iopub.status.idle":"2021-11-16T18:20:28.158832Z","shell.execute_reply.started":"2021-11-16T18:20:28.090463Z","shell.execute_reply":"2021-11-16T18:20:28.157734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = models_lgbm\nXs = dict(lastXs)\nfor i, (df_test, df_pred) in enumerate(iter_test):\n    for j , row in df_test.iterrows():\n        ID = row['Asset_ID']\n        model = models[ID]\n        Xs[ID] = Xs[ID].shift(-1)\n        Xs[ID].iloc[-1] = row[1:]\n        \n        x_test = get_features(Xs[ID])\n        y_pred = model.predict(x_test[-1:])[0]\n        \n        df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = y_pred\n        \n#         # Print just one sample row to get a feeling of what it looks like\n#         if i == 0 and j == 0:\n#             display(x_test)\n\n#     # Display the first prediction dataframe\n#     if i == 0:\n#         display(df_pred)\n\n    # Send submissions\n    env.predict(df_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:20:28.499344Z","iopub.execute_input":"2021-11-16T18:20:28.499642Z","iopub.status.idle":"2021-11-16T18:20:29.183486Z","shell.execute_reply.started":"2021-11-16T18:20:28.499606Z","shell.execute_reply":"2021-11-16T18:20:29.182544Z"}},"execution_count":null,"outputs":[]}]}